/////////////////////////////////////////////////////////////////////////////////////////////////////
BRIEF INSTRUCTIONS FOR OPTIMIZATION:
/////////////////////////////////////////////////////////////////////////////////////////////////////
In doThetaTemplates.py:
- Optimization should be done w/o systematics since it takes too much computing time with shapes
- Check bkgList, sigList, dataList, and other ewk/top/qcd background group list to make sure they include
all the processes you want.
- Check the categories isEMlist,nttaglist,nWtaglist, and nbtaglist
In doCondorThetaTemplates.py:
- Give the list of cuts you want to explore and the output directory information

Once the templates are produced, the limits can be run using the scripts in makeLimits/. 

/////////////////////////////////////////////////////////////////////////////////////////////////////
DETAILED INSTRUCTIONS:
/////////////////////////////////////////////////////////////////////////////////////////////////////
The main code to make histograms is "doThetaTemplates.py":
To be modified by user (listed in the order as they appear in the script):
	- input directory (step1 or step2)
	- list of samples to be run for signals, backgrounds, and data
	- group the background processes into "ewk", "qcd", "top", "ttjets", 
	etc (no need to modify unless samples and thus their names change). Also, note that
	yields/plotting are setup for "ewk/top/qcd" grouped backgrounds. If detailed background
	processes wanted, the implementations has to be completed!
	- systematics: they have to be defined in "analyze.py" and corresponding samples must exist.
	The systematics can be turned off if only simple plots wanted without total uncertainty bands
	or only considering the normalization uncertainties in the limit calculation!
	- Q^2 needs to be taken care of separately
	- Give the list of cuts to be applied! New cuts can be included in "cutList" as long as
	they are also added in "analyze.py" to "cut" string and also add it to "cutString" variable in "makeTemplates.py"
	- modify the output directory names, etc
	- modify the normalization uncertainties
	- give the discriminants in "plotList". In the definition, give a name to distribution 
	as a key to the dictionary, name of the variable in ljmet trees, x-axis label, and the desired binning
/////////////////////////////////////////////////////////////////////////////////////////////////////
"analyze.py":
This does not need a modification, if you are only changing the cuts that are already there and 
using only the systematics defined there (or not using the systematics). If you want a different
categorization, this also has to be implemented here! Currently, it can categorize events into E/M,
and any number of top/W/b tagging categories.
/////////////////////////////////////////////////////////////////////////////////////////////////////
"samples.py":
It needs definitions of all the samples that are being analyzed. This is for easy access to input files!
/////////////////////////////////////////////////////////////////////////////////////////////////////
"weights.py":
This is where primary MC weights are defined. Each sample again must have a defined weight here with
number of generated events, x-sec, and the luminosity
/////////////////////////////////////////////////////////////////////////////////////////////////////
"doThetaTemplates.py" can be run interactively by simply doing "python doThetaTemplates.py". In
this case, templates for a single set of cuts will be produced.
If you want to do a basic cut optimization, use "doCondorThetaTemplates.py" and "doCondorThetaTemplates.sh". 
Before running condor scripts, "doThetaTemplates.py" has to be modified with the configuration wanted.
If additional cuts wanted to be optimized, this can be easily implemented by following the same 
implementation procedure as the others!
Although the optimization with the shape uncertainties can be done in principle, this can require significant
amount of computation time and sources. Therefore, switch off the systematics when doing optimization. If you
are going wild and insist on including the systematics, then keep in mind that the pdf and renormalization/
factorization uncertainties are not implemented here. Contact Sinan_Sagir@brown.edu if you need this!!
/////////////////////////////////////////////////////////////////////////////////////////////////////
Once the templates are produced, there are number of things you can do before limit calculation.
1) Plotting the theta templates using "plotThetaTemplates.py":
	- give luminosity info, discriminant name and the cut string that you want to plot
	- give 2 signals to show on the stack plots
	- do you have the systematics in the templates? If so, which ones (give the same names as the ones used in 
	"analyze.py")? Turn off the bools if you don't have the shapes
	- if you have the shape systematics, you can produce two types of plots; one with the uncertainty bands are separated in
	the lower panel and another one with only the total uncertainty band using "doOneBand".
	- template directory needs to be specified.
	- check if you have the right normalization systematics, they will be added to error bands
	- note that the "QCD" process will not be shown on the plots if it is less than 0.5% of the background
	- if you'd like to change plot labels, etc, use "formatLowerHist" and "formatUpperHist"
	- "isRebinned" is a postfix that is attached to root file names when you rebin the histograms or do other things!

2) Rebinning the theta templates using "modifyBinning.py":
	- give the template directory information.
	- this script can modify the binning for a given statistical uncertainty threshold, 
	but the implementation hasn't been completely tested, so use at your own risk.
	- You can also rebin the histograms by giving a custom binning choice in "xbinsList"

3) "splitChannels.py":
	- This script can be used for multiple purposes: For example,
		* split templates into different channels (to run limits separately)
		* remove some of the shape uncertainties (for debugging the results)
		* normalize some of the shape uncertainties in order to use only the shape (for example
		muF, muR, and pdf are not normalized to nominal in the template maker, so it has to be done here!!)
		* there are examples in the script showing how to do these
	- give the template directory information.
	- use the rebinned templates for this
	- give a unique postfix to files for each configuration instead of just "modified"

